"""
Mike-George Verros
ITC6010A1 - NATURAL LANGUAGE PROCESSING - SPRING TERM 2021
HW#1
I create simple tests in order to be 100% confident that one slice change does not affect the results
"""

from functions.functions import *

print('\n\n Test With sample-text.txt \n\n')

text = get_the_content_of_a_file(get_sample_text_file_path())
tokenized_list = tokenization(text)
file_lang = identify_lang_of_a_given_file(text)

assert sum_of_paragraphs(text) == 8, 'Should be 8'
assert sum_of_sentences(text) == 30, 'Should be 30'
assert tokenized_list == ['Here', 'are', 'some', 'random', 'sentences', '.', 'If', 'you', 'can', 'really', 'see', 'the', 'future', ',', 'you', 'could', 'have', 'prevented', 'all', 'of', 'this', '!', 'I', 'just', 'have', 'to', 'report', 'a', 'really', 'beautiful', 'example', 'I', 'heard', 'on', 'my', 'favorite', 'public', 'radio', 'station', 'on', 'Feb', '.', '16', 'during', 'their', 'recent', 'fund', 'drive', '.', 'I', 'have', 'met', 'a', 'member', 'of', 'their', 'developmember', 'staff', 'and', 'been', 'interviewed', 'by', 'her', '.', 'I', 'will', 'name', 'her', 'simply', 'because', 'she', 'might', 'be', 'embarrassed', 'and', 'I', 'would', 'not', 'want', 'to', 'cause', 'that', '.', 'This', 'powerful', 'true', 'story', 'of', 'human', 'decency', 'and', 'courage', ',', 'so', 'rare', 'in', 'the', 'tragic', 'annals', 'of', 'World', 'War', 'II', ',', 'is', 'badly', 'spoiled', 'by', 'terrible', 'writing', '.', 'Many', 'of', 'the', 'reviews', 'here', 'explain', 'just', 'what', 'makes', 'the', 'writing', 'so', 'bad', '(', 'e', '.', 'g', '.', ',', 'John', 'Sollami', 'is', '3-star', 'review', 'and', 'comments', 'on', 'it', ')', 'so', 'I', 'will', 'do', 'that', 'here', '.', 'It', 'is', 'repetitive', ',', 'slow', ',', 'not', 'interesting', 'and', 'I', 'think', 'if', 'I', 'have', 'to', 'read', 'the', 'word', '"saumensch"', 'or', '"saukerl"', 'one', 'more', 'time', ',', 'I', 'will', 'be', 'done', 'with', 'this', 'book', 'forever', '.', 'Because', 'you', 'have', 'not', 'sopped', 'up', 'enough', 'of', 'that', 'yet', 'in', 'your', 'life', ',', 'right?', 'By', 'far', 'my', 'favorite', 'book', '!', 'The', 'language', 'is', 'beautiful', 'and', 'imaginative', ',', 'and', 'you', 'can', 'help', 'but', 'fall', 'in', 'love', 'with', 'the', 'characters', '.', 'You', 'have', 'to', 'have', 'studied', 'WW2', 'extensively', 'along', 'with', 'the', 'love', 'for', 'fiction', 'and', 'the', 'struggle', 'theme', 'that', 'is', 'projected', 'through', 'this', 'whole', 'book', '.', 'Little', 'do', 'they', 'know', 'he', 'has', 'fled', 'to', 'london', 'and', 'they', 'are', 'forced', 'to', 'stay', 'with', 'Marie', 'is', 'great', 'uncle', 'Etienne', 'where', 'they', 'remain', 'hidden', '.', 'Intriguing', 'story', '.', 'I', 'love', 'how', 'the', 'book', 'is', 'arranged', ':', 'parallel', 'narration', ',', 'third-person', 'perspective', ',', 'chapter', 'by', 'chapter', 'with', 'a', 'changing', 'view', 'brought', 'by', 'new', 'characters', 'of', 'what', 'is', 'happening', 'along', 'the', 'theme', '.', 'The', 'characters', 'are', 'all', 'connected', 'yet', 'seemingly', 'disconnected', '.', 'It', 'is', 'like', 'watching', 'a', 'movie', 'with', 'the', 'reader', 'as', 'the', 'camera', ':', 'we', 'know', 'all', 'the', 'sides', 'but', 'we', 'do', 'not', 'know', 'how', 'it', 'is', 'going', '.', 'It', 'keeps', 'the', 'reader', 'engaged', '.', 'Definitely', 'a', 'page-turner', '.', 'He', 'drives', 'slow', ',', 'uses', 'a', 'shoehorn', ',', 'does', 'not', 'know', 'about', 'hybrid', 'cars', ',', 'disagrees', 'with', 'using', 'credit', 'cards', 'for', 'shopping', ',', 'does', 'not', 'use', 'a', 'coffee', 'maker', 'because', 'a', 'percolator', 'is', 'perfectly', 'fine', ',', 'etc', '.', 'I', 'am', 'sorry', 'but', 'age', '59', 'just', 'does', 'not', 'fit', 'the', 'story', '.', 'Ove', 'comes', 'to', 'like', 'the', 'cat', 'and', 'suddenly', 'they', 'are', 'best', 'friends', '.', 'At', 'least', 'the', 'story', 'is', 'predictability', 'saved', 'me', 'from', 'fretting', 'incessantly', 'about', 'the', 'cat', '.', 'She', 'is', 'a', 'take-no-prisoners', 'fireball', '.', 'He', 'is', 'a', 'sweet-talking', 'charmer', '.', 'It', 'could', 'be', 'love', '.', '.', '.', 'if', 'they', 'do', 'not', 'kill', 'each', 'other', 'first', '.', 'Enemies', 'to', 'lovers', 'romance', '.', 'It', 'would', 'not', 'have', '(', 'would', 'not', 'of', 'had?', ')', 'bothered', 'me', 'if', 'it', 'only', 'appeared', 'in', 'dialogue', ',', 'but', 'I', 'recall', 'it', 'occured', 'several', 'times', 'in', 'the', 'narrative', '(', 'by', '.', '.', '.', '.', 'I', 'started', 'this', 'comment', 'to', 'say', 'that', 'the', 'explanation', 'seemed', 'less', 'likely', 'in', 'examples', 'with', 'things', 'separating', 'the', 'and', ')', '.']
assert sum_of_distinct_word_types(tokenized_list) == {'NN': 188, 'NNS': 28, 'VBD': 19, 'VBG': 13, 'RB': 11, 'AT': 6, 'CD': 2}
assert token_frequency(tokenized_list) == [('.', 35), ('the', 21), (',', 17), ('is', 14), ('I', 13), ('and', 11), ('a', 10), ('not', 10), ('to', 9), ('have', 8), ('of', 8), ('with', 8), ('in', 6), ('It', 5), ('by', 5), ('that', 5), ('they', 5), ('are', 4), ('book', 4), ('but', 4), ('do', 4), ('it', 4), ('know', 4), ('love', 4), ('story', 4), ('this', 4), ('you', 4), ('(', 3), (')', 3), ('all', 3), ('be', 3), ('characters', 3), ('does', 3), ('if', 3), ('just', 3), ('on', 3), ('so', 3), ('will', 3), ('would', 3), ('!', 2), (':', 2), ('He', 2), ('The', 2), ('about', 2), ('along', 2), ('beautiful', 2), ('because', 2), ('can', 2), ('cat', 2), ('chapter', 2), ('could', 2), ('favorite', 2), ('for', 2), ('here', 2), ('her', 2), ('how', 2), ('like', 2), ('me', 2), ('my', 2), ('reader', 2), ('really', 2), ('slow', 2), ('their', 2), ('theme', 2), ('we', 2), ('what', 2), ('writing', 2), ('yet', 2), ('"saukerl"', 1), ('"saumensch"', 1), ('16', 1), ('3-star', 1), ('59', 1), ('At', 1), ('Because', 1), ('By', 1), ('Definitely', 1), ('Enemies', 1), ('Etienne', 1), ('Feb', 1), ('Here', 1), ('II', 1), ('If', 1), ('Intriguing', 1), ('John', 1), ('Little', 1), ('Many', 1), ('Marie', 1), ('Ove', 1), ('She', 1), ('Sollami', 1), ('This', 1), ('WW2', 1), ('War', 1), ('World', 1), ('You', 1), ('age', 1), ('am', 1), ('annals', 1), ('appeared', 1), ('arranged', 1), ('as', 1), ('badly', 1), ('bad', 1), ('been', 1), ('best', 1), ('bothered', 1), ('brought', 1), ('camera', 1), ('cards', 1), ('cars', 1), ('cause', 1), ('changing', 1), ('charmer', 1), ('coffee', 1), ('comes', 1), ('comments', 1), ('comment', 1), ('connected', 1), ('courage', 1), ('credit', 1), ('decency', 1), ('developmember', 1), ('dialogue', 1), ('disagrees', 1), ('disconnected', 1), ('done', 1), ('drives', 1), ('drive', 1), ('during', 1), ('each', 1), ('embarrassed', 1), ('engaged', 1), ('enough', 1), ('etc', 1), ('examples', 1), ('example', 1), ('explain', 1), ('explanation', 1), ('extensively', 1), ('e', 1), ('fall', 1), ('far', 1), ('fiction', 1), ('fine', 1), ('fireball', 1), ('first', 1), ('fit', 1), ('fled', 1), ('forced', 1), ('forever', 1), ('fretting', 1), ('friends', 1), ('from', 1), ('fund', 1), ('future', 1), ('going', 1), ('great', 1), ('g', 1), ('had?', 1), ('happening', 1), ('has', 1), ('heard', 1), ('help', 1), ('he', 1), ('hidden', 1), ('human', 1), ('hybrid', 1), ('imaginative', 1), ('incessantly', 1), ('interesting', 1), ('interviewed', 1), ('keeps', 1), ('kill', 1), ('language', 1), ('least', 1), ('less', 1), ('life', 1), ('likely', 1), ('london', 1), ('lovers', 1), ('maker', 1), ('makes', 1), ('member', 1), ('met', 1), ('might', 1), ('more', 1), ('movie', 1), ('name', 1), ('narration', 1), ('narrative', 1), ('new', 1), ('occured', 1), ('one', 1), ('only', 1), ('or', 1), ('other', 1), ('page-turner', 1), ('parallel', 1), ('percolator', 1), ('perfectly', 1), ('perspective', 1), ('powerful', 1), ('predictability', 1), ('prevented', 1), ('projected', 1), ('public', 1), ('radio', 1), ('random', 1), ('rare', 1), ('read', 1), ('recall', 1), ('recent', 1), ('remain', 1), ('repetitive', 1), ('report', 1), ('reviews', 1), ('review', 1), ('right?', 1), ('romance', 1), ('saved', 1), ('say', 1), ('seemed', 1), ('seemingly', 1), ('see', 1), ('sentences', 1), ('separating', 1), ('several', 1), ('she', 1), ('shoehorn', 1), ('shopping', 1), ('sides', 1), ('simply', 1), ('some', 1), ('sopped', 1), ('sorry', 1), ('spoiled', 1), ('staff', 1), ('started', 1), ('station', 1), ('stay', 1), ('struggle', 1), ('studied', 1), ('suddenly', 1), ('sweet-talking', 1), ('take-no-prisoners', 1), ('terrible', 1), ('things', 1), ('think', 1), ('third-person', 1), ('through', 1), ('times', 1), ('time', 1), ('tragic', 1), ('true', 1), ('uncle', 1), ('up', 1), ('uses', 1), ('use', 1), ('using', 1), ('view', 1), ('want', 1), ('watching', 1), ('where', 1), ('whole', 1), ('word', 1), ('your', 1)]
assert remove_stop_words(tokenized_list, file_lang) == ['Here', 'random', 'sentences', '.', 'If', 'really', 'see', 'future', ',', 'could', 'prevented', '!', 'I', 'report', 'really', 'beautiful', 'example', 'I', 'heard', 'favorite', 'public', 'radio', 'station', 'Feb', '.', '16', 'recent', 'fund', 'drive', '.', 'I', 'met', 'member', 'developmember', 'staff', 'interviewed', '.', 'I', 'name', 'simply', 'might', 'embarrassed', 'I', 'would', 'want', 'cause', '.', 'This', 'powerful', 'true', 'story', 'human', 'decency', 'courage', ',', 'rare', 'tragic', 'annals', 'World', 'War', 'II', ',', 'badly', 'spoiled', 'terrible', 'writing', '.', 'Many', 'reviews', 'explain', 'makes', 'writing', 'bad', '(', 'e', '.', 'g', '.', ',', 'John', 'Sollami', '3-star', 'review', 'comments', ')', 'I', '.', 'It', 'repetitive', ',', 'slow', ',', 'interesting', 'I', 'think', 'I', 'read', 'word', '"saumensch"', '"saukerl"', 'one', 'time', ',', 'I', 'done', 'book', 'forever', '.', 'Because', 'sopped', 'enough', 'yet', 'life', ',', 'right?', 'By', 'far', 'favorite', 'book', '!', 'The', 'language', 'beautiful', 'imaginative', ',', 'help', 'fall', 'love', 'characters', '.', 'You', 'studied', 'WW2', 'extensively', 'along', 'love', 'fiction', 'struggle', 'theme', 'projected', 'whole', 'book', '.', 'Little', 'know', 'fled', 'london', 'forced', 'stay', 'Marie', 'great', 'uncle', 'Etienne', 'remain', 'hidden', '.', 'Intriguing', 'story', '.', 'I', 'love', 'book', 'arranged', ':', 'parallel', 'narration', ',', 'third-person', 'perspective', ',', 'chapter', 'chapter', 'changing', 'view', 'brought', 'new', 'characters', 'happening', 'along', 'theme', '.', 'The', 'characters', 'connected', 'yet', 'seemingly', 'disconnected', '.', 'It', 'like', 'watching', 'movie', 'reader', 'camera', ':', 'know', 'sides', 'know', 'going', '.', 'It', 'keeps', 'reader', 'engaged', '.', 'Definitely', 'page-turner', '.', 'He', 'drives', 'slow', ',', 'uses', 'shoehorn', ',', 'know', 'hybrid', 'cars', ',', 'disagrees', 'using', 'credit', 'cards', 'shopping', ',', 'use', 'coffee', 'maker', 'percolator', 'perfectly', 'fine', ',', 'etc', '.', 'I', 'sorry', 'age', '59', 'fit', 'story', '.', 'Ove', 'comes', 'like', 'cat', 'suddenly', 'best', 'friends', '.', 'At', 'least', 'story', 'predictability', 'saved', 'fretting', 'incessantly', 'cat', '.', 'She', 'take-no-prisoners', 'fireball', '.', 'He', 'sweet-talking', 'charmer', '.', 'It', 'could', 'love', '.', '.', '.', 'kill', 'first', '.', 'Enemies', 'lovers', 'romance', '.', 'It', 'would', '(', 'would', 'had?', ')', 'bothered', 'appeared', 'dialogue', ',', 'I', 'recall', 'occured', 'several', 'times', 'narrative', '(', '.', '.', '.', '.', 'I', 'started', 'comment', 'say', 'explanation', 'seemed', 'less', 'likely', 'examples', 'things', 'separating', ')', '.']

print('\n\n Test With sample1.txt \n\n')

text_sample_1 = get_the_content_of_a_file('tests/files/sample1.txt')
tokenized_list_sample_1 = tokenization(text_sample_1)
file_lang = identify_lang_of_a_given_file(text_sample_1)

assert sum_of_paragraphs(text_sample_1) == 4, 'Should be 4'
assert sum_of_sentences(text_sample_1) == 50, 'Should be 50'
assert tokenized_list_sample_1 == ['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Morbi', 'bibendum', 'velit', 'eget', 'quam', 'sollicitudin', 'dapibus', '.', 'Nulla', 'efficitur', 'lobortis', 'lectus', 'et', 'lobortis', '.', 'Suspendisse', 'molestie', 'sem', 'nec', 'nibh', 'efficitur', 'gravida', '.', 'Aliquam', 'erat', 'volutpat', '.', 'Curabitur', 'a', 'orci', 'iaculis', ',', 'laoreet', 'diam', 'non', ',', 'maximus', 'libero', '.', 'Curabitur', 'faucibus', 'leo', 'sapien', ',', 'non', 'sodales', 'risus', 'blandit', 'vitae', '.', 'Phasellus', 'a', 'nisl', 'ut', 'nulla', 'fringilla', 'tristique', '.', 'Duis', 'dapibus', 'leo', 'nec', 'enim', 'convallis', 'tristique', '.', 'Nunc', 'sollicitudin', 'ipsum', 'id', 'mi', 'sodales', 'consectetur', '.', 'Donec', 'eget', 'ipsum', 'maximus', ',', 'gravida', 'risus', 'quis', ',', 'commodo', 'quam', '.', 'Fusce', 'tempor', ',', 'odio', 'in', 'malesuada', 'egestas', ',', 'tortor', 'nisl', 'fermentum', 'ex', ',', 'id', 'eleifend', 'orci', 'ipsum', 'nec', 'velit', '.', 'Pellentesque', 'libero', 'metus', ',', 'viverra', 'nec', 'rhoncus', 'quis', ',', 'pulvinar', 'nec', 'massa', '.', 'Integer', 'pharetra', 'eu', 'sem', 'sit', 'amet', 'varius', '.', 'Praesent', 'consectetur', 'euismod', 'turpis', 'non', 'semper', '.', 'Sed', 'arcu', 'libero', ',', 'bibendum', 'ac', 'congue', 'vel', ',', 'laoreet', 'ac', 'quam', '.', 'Pellentesque', 'nibh', 'tortor', ',', 'porta', 'et', 'volutpat', 'sit', 'amet', ',', 'vestibulum', 'accumsan', 'nulla', '.', 'Sed', 'sem', 'nisi', ',', 'posuere', 'eu', 'sem', 'sed', ',', 'rutrum', 'tempus', 'neque', '.', 'Duis', 'a', 'auctor', 'odio', '.', 'Pellentesque', 'tempus', 'dolor', 'libero', ',', 'ut', 'tempus', 'purus', 'vulputate', 'quis', '.', 'Maecenas', 'semper', 'euismod', 'finibus', '.', 'Etiam', 'sodales', 'lectus', 'id', 'erat', 'lobortis', 'aliquet', '.', 'Duis', 'tortor', 'ipsum', ',', 'laoreet', 'vitae', 'nunc', 'quis', ',', 'tempor', 'pellentesque', 'justo', '.', 'Sed', 'tempor', ',', 'massa', 'non', 'porta', 'bibendum', ',', 'diam', 'purus', 'ultricies', 'ipsum', ',', 'ut', 'lacinia', 'massa', 'mi', 'eu', 'justo', '.', 'In', 'nec', 'quam', 'nec', 'quam', 'finibus', 'aliquet', 'nec', 'ac', 'magna', '.', 'In', 'in', 'porta', 'nunc', ',', 'eget', 'viverra', 'sem', '.', 'Nulla', 'eget', 'enim', 'mauris', '.', 'Maecenas', 'blandit', ',', 'massa', 'sed', 'ultricies', 'lobortis', ',', 'magna', 'velit', 'lacinia', 'lectus', ',', 'vel', 'pretium', 'sem', 'leo', 'vitae', 'risus', '.', 'Morbi', 'sed', 'molestie', 'ex', '.', 'Nullam', 'suscipit', 'orci', 'sit', 'amet', 'turpis', 'commodo', 'aliquam', '.', 'Aliquam', 'mattis', 'hendrerit', 'est', 'vel', 'eleifend', '.', 'Nunc', 'nulla', 'arcu', ',', 'eleifend', 'in', 'accumsan', 'at', ',', 'condimentum', 'in', 'velit', '.', 'Donec', 'eu', 'sapien', 'eu', 'leo', 'tristique', 'accumsan', 'sed', 'in', 'dolor', '.', 'In', 'hac', 'habitasse', 'platea', 'dictumst', '.', 'Aenean', 'id', 'tempus', 'neque', '.', 'Nam', 'sit', 'amet', 'tortor', 'imperdiet', ',', 'vulputate', 'nunc', 'quis', ',', 'imperdiet', 'sem', '.', 'Proin', 'suscipit', 'nunc', 'lacus', ',', 'sit', 'amet', 'efficitur', 'elit', 'pulvinar', 'in', '.', 'Maecenas', 'rhoncus', 'est', 'non', 'risus', 'viverra', ',', 'vel', 'congue', 'felis', 'pellentesque', '.', 'Quisque', 'viverra', 'posuere', 'nibh', ',', 'vel', 'lobortis', 'nunc', 'maximus', 'et', '.', 'Aenean', 'congue', 'est', 'et', 'gravida', 'euismod', '.', 'Donec', 'accumsan', 'blandit', 'finibus', '.', 'Phasellus', 'eleifend', 'justo', 'at', 'aliquam', 'condimentum', '.', 'Donec', 'lacinia', 'ipsum', 'nec', 'eros', 'euismod', ',', 'ultricies', 'tempor', 'arcu', 'finibus', '.', 'Phasellus', 'varius', 'condimentum', 'massa', 'sed', 'fringilla', '.', 'Curabitur', 'eu', 'luctus', 'ante', '.', 'Curabitur', 'maximus', 'nisl', 'vitae', 'dui', 'condimentum', 'mollis', '.', 'Nulla', 'porttitor', 'diam', 'sed', 'pharetra', 'hendrerit', '.', 'Nulla', 'ut', 'orci', 'ante', '.', 'Maecenas', 'volutpat', 'dignissim', 'pretium', '.', 'Etiam', 'euismod', 'tincidunt', 'orci', ',', 'sit', 'amet', 'semper', 'turpis', 'dignissim', 'nec', '.']
assert sum_of_distinct_word_types(tokenized_list_sample_1) == {'NN': 96, 'NNS': 29, 'AT': 15, 'VBD': 2, 'VBG': 1}
assert token_frequency(tokenized_list_sample_1) == [('.', 50), (',', 36), ('nec', 10), ('amet', 7), ('ipsum', 7), ('sem', 7), ('sit', 7), ('eu', 6), ('in', 6), ('sed', 6), ('euismod', 5), ('lobortis', 5), ('massa', 5), ('non', 5), ('nunc', 5), ('orci', 5), ('quam', 5), ('quis', 5), ('vel', 5), ('Curabitur', 4), ('Donec', 4), ('Maecenas', 4), ('Nulla', 4), ('accumsan', 4), ('condimentum', 4), ('eget', 4), ('eleifend', 4), ('et', 4), ('finibus', 4), ('id', 4), ('leo', 4), ('libero', 4), ('maximus', 4), ('risus', 4), ('tempor', 4), ('tempus', 4), ('tortor', 4), ('ut', 4), ('velit', 4), ('vitae', 4), ('viverra', 4), ('Duis', 3), ('In', 3), ('Pellentesque', 3), ('Phasellus', 3), ('Sed', 3), ('ac', 3), ('arcu', 3), ('a', 3), ('bibendum', 3), ('blandit', 3), ('congue', 3), ('consectetur', 3), ('diam', 3), ('dolor', 3), ('efficitur', 3), ('est', 3), ('gravida', 3), ('justo', 3), ('lacinia', 3), ('laoreet', 3), ('lectus', 3), ('nibh', 3), ('nisl', 3), ('nulla', 3), ('porta', 3), ('semper', 3), ('sodales', 3), ('tristique', 3), ('turpis', 3), ('ultricies', 3), ('volutpat', 3), ('Aenean', 2), ('Aliquam', 2), ('Etiam', 2), ('Morbi', 2), ('Nunc', 2), ('aliquam', 2), ('aliquet', 2), ('ante', 2), ('at', 2), ('commodo', 2), ('dapibus', 2), ('dignissim', 2), ('elit', 2), ('enim', 2), ('erat', 2), ('ex', 2), ('fringilla', 2), ('hendrerit', 2), ('imperdiet', 2), ('magna', 2), ('mi', 2), ('molestie', 2), ('neque', 2), ('odio', 2), ('pellentesque', 2), ('pharetra', 2), ('posuere', 2), ('pretium', 2), ('pulvinar', 2), ('purus', 2), ('rhoncus', 2), ('sapien', 2), ('sollicitudin', 2), ('suscipit', 2), ('varius', 2), ('vulputate', 2), ('Fusce', 1), ('Integer', 1), ('Lorem', 1), ('Nam', 1), ('Nullam', 1), ('Praesent', 1), ('Proin', 1), ('Quisque', 1), ('Suspendisse', 1), ('adipiscing', 1), ('auctor', 1), ('convallis', 1), ('dictumst', 1), ('dui', 1), ('egestas', 1), ('eros', 1), ('faucibus', 1), ('felis', 1), ('fermentum', 1), ('habitasse', 1), ('hac', 1), ('iaculis', 1), ('lacus', 1), ('luctus', 1), ('malesuada', 1), ('mattis', 1), ('mauris', 1), ('metus', 1), ('mollis', 1), ('nisi', 1), ('platea', 1), ('porttitor', 1), ('rutrum', 1), ('tincidunt', 1), ('vestibulum', 1)]
assert remove_stop_words(tokenized_list_sample_1, file_lang) == ['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Morbi', 'bibendum', 'velit', 'eget', 'quam', 'sollicitudin', 'dapibus', '.', 'Nulla', 'efficitur', 'lobortis', 'lectus', 'et', 'lobortis', '.', 'Suspendisse', 'molestie', 'sem', 'nec', 'nibh', 'efficitur', 'gravida', '.', 'Aliquam', 'erat', 'volutpat', '.', 'Curabitur', 'a', 'orci', 'iaculis', ',', 'laoreet', 'diam', 'non', ',', 'maximus', 'libero', '.', 'Curabitur', 'faucibus', 'leo', 'sapien', ',', 'non', 'sodales', 'risus', 'blandit', 'vitae', '.', 'Phasellus', 'a', 'nisl', 'ut', 'nulla', 'fringilla', 'tristique', '.', 'Duis', 'dapibus', 'leo', 'nec', 'enim', 'convallis', 'tristique', '.', 'Nunc', 'sollicitudin', 'ipsum', 'id', 'mi', 'sodales', 'consectetur', '.', 'Donec', 'eget', 'ipsum', 'maximus', ',', 'gravida', 'risus', 'quis', ',', 'commodo', 'quam', '.', 'Fusce', 'tempor', ',', 'odio', 'in', 'malesuada', 'egestas', ',', 'tortor', 'nisl', 'fermentum', 'ex', ',', 'id', 'eleifend', 'orci', 'ipsum', 'nec', 'velit', '.', 'Pellentesque', 'libero', 'metus', ',', 'viverra', 'nec', 'rhoncus', 'quis', ',', 'pulvinar', 'nec', 'massa', '.', 'Integer', 'pharetra', 'eu', 'sem', 'sit', 'amet', 'varius', '.', 'Praesent', 'consectetur', 'euismod', 'turpis', 'non', 'semper', '.', 'Sed', 'arcu', 'libero', ',', 'bibendum', 'ac', 'congue', 'vel', ',', 'laoreet', 'ac', 'quam', '.', 'Pellentesque', 'nibh', 'tortor', ',', 'porta', 'et', 'volutpat', 'sit', 'amet', ',', 'vestibulum', 'accumsan', 'nulla', '.', 'Sed', 'sem', 'nisi', ',', 'posuere', 'eu', 'sem', 'sed', ',', 'rutrum', 'tempus', 'neque', '.', 'Duis', 'a', 'auctor', 'odio', '.', 'Pellentesque', 'tempus', 'dolor', 'libero', ',', 'ut', 'tempus', 'purus', 'vulputate', 'quis', '.', 'Maecenas', 'semper', 'euismod', 'finibus', '.', 'Etiam', 'sodales', 'lectus', 'id', 'erat', 'lobortis', 'aliquet', '.', 'Duis', 'tortor', 'ipsum', ',', 'laoreet', 'vitae', 'nunc', 'quis', ',', 'tempor', 'pellentesque', 'justo', '.', 'Sed', 'tempor', ',', 'massa', 'non', 'porta', 'bibendum', ',', 'diam', 'purus', 'ultricies', 'ipsum', ',', 'ut', 'lacinia', 'massa', 'mi', 'eu', 'justo', '.', 'In', 'nec', 'quam', 'nec', 'quam', 'finibus', 'aliquet', 'nec', 'ac', 'magna', '.', 'In', 'in', 'porta', 'nunc', ',', 'eget', 'viverra', 'sem', '.', 'Nulla', 'eget', 'enim', 'mauris', '.', 'Maecenas', 'blandit', ',', 'massa', 'sed', 'ultricies', 'lobortis', ',', 'magna', 'velit', 'lacinia', 'lectus', ',', 'vel', 'pretium', 'sem', 'leo', 'vitae', 'risus', '.', 'Morbi', 'sed', 'molestie', 'ex', '.', 'Nullam', 'suscipit', 'orci', 'sit', 'amet', 'turpis', 'commodo', 'aliquam', '.', 'Aliquam', 'mattis', 'hendrerit', 'est', 'vel', 'eleifend', '.', 'Nunc', 'nulla', 'arcu', ',', 'eleifend', 'in', 'accumsan', 'at', ',', 'condimentum', 'in', 'velit', '.', 'Donec', 'eu', 'sapien', 'eu', 'leo', 'tristique', 'accumsan', 'sed', 'in', 'dolor', '.', 'In', 'hac', 'habitasse', 'platea', 'dictumst', '.', 'Aenean', 'id', 'tempus', 'neque', '.', 'Nam', 'sit', 'amet', 'tortor', 'imperdiet', ',', 'vulputate', 'nunc', 'quis', ',', 'imperdiet', 'sem', '.', 'Proin', 'suscipit', 'nunc', 'lacus', ',', 'sit', 'amet', 'efficitur', 'elit', 'pulvinar', 'in', '.', 'Maecenas', 'rhoncus', 'est', 'non', 'risus', 'viverra', ',', 'vel', 'congue', 'felis', 'pellentesque', '.', 'Quisque', 'viverra', 'posuere', 'nibh', ',', 'vel', 'lobortis', 'nunc', 'maximus', 'et', '.', 'Aenean', 'congue', 'est', 'et', 'gravida', 'euismod', '.', 'Donec', 'accumsan', 'blandit', 'finibus', '.', 'Phasellus', 'eleifend', 'justo', 'at', 'aliquam', 'condimentum', '.', 'Donec', 'lacinia', 'ipsum', 'nec', 'eros', 'euismod', ',', 'ultricies', 'tempor', 'arcu', 'finibus', '.', 'Phasellus', 'varius', 'condimentum', 'massa', 'sed', 'fringilla', '.', 'Curabitur', 'eu', 'luctus', 'ante', '.', 'Curabitur', 'maximus', 'nisl', 'vitae', 'dui', 'condimentum', 'mollis', '.', 'Nulla', 'porttitor', 'diam', 'sed', 'pharetra', 'hendrerit', '.', 'Nulla', 'ut', 'orci', 'ante', '.', 'Maecenas', 'volutpat', 'dignissim', 'pretium', '.', 'Etiam', 'euismod', 'tincidunt', 'orci', ',', 'sit', 'amet', 'semper', 'turpis', 'dignissim', 'nec', '.']

print('\n\n Test With sample2.txt \n\n')

text_sample_2 = get_the_content_of_a_file('tests/files/sample2.txt')
tokenized_list_sample_2 = tokenization(text_sample_2)
file_lang = identify_lang_of_a_given_file(text_sample_2)

assert sum_of_paragraphs(text_sample_2) == 1, 'Should be 1'
assert sum_of_sentences(text_sample_2) == 10, 'Should be 10'
assert tokenized_list_sample_2 == ['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Sed', 'congue', 'dapibus', 'cursus', '.', 'Aenean', 'volutpat', 'ex', 'sit', 'amet', 'purus', 'tincidunt', 'accumsan', '.', 'In', 'non', 'rhoncus', 'augue', '.', 'Maecenas', 'pulvinar', 'placerat', 'accumsan', '.', 'Cras', 'vehicula', ',', 'ipsum', 'non', 'condimentum', 'tristique', ',', 'lacus', 'nulla', 'cursus', 'sem', ',', 'et', 'feugiat', 'massa', 'libero', 'et', 'massa', '.', 'Vivamus', 'ut', 'magna', 'ac', 'massa', 'egestas', 'iaculis', 'a', 'sit', 'amet', 'nibh', '.', 'Quisque', 'sed', 'ante', 'sodales', ',', 'cursus', 'sapien', 'ac', ',', 'finibus', 'urna', '.', 'Curabitur', 'vitae', 'dolor', 'in', 'odio', 'viverra', 'scelerisque', '.', 'Donec', 'condimentum', 'leo', 'justo', ',', 'quis', 'commodo', 'nisl', 'semper', 'vel', '.']
assert sum_of_distinct_word_types(tokenized_list_sample_2) == {'NN': 42, 'NNS': 13, 'AT': 9, 'VBD': 2, 'VBG': 1}
assert token_frequency(tokenized_list_sample_2) == [('.', 10), (',', 7), ('amet', 3), ('cursus', 3), ('massa', 3), ('sit', 3), ('accumsan', 2), ('ac', 2), ('condimentum', 2), ('dolor', 2), ('et', 2), ('ipsum', 2), ('non', 2), ('Aenean', 1), ('Cras', 1), ('Curabitur', 1), ('Donec', 1), ('In', 1), ('Lorem', 1), ('Maecenas', 1), ('Quisque', 1), ('Sed', 1), ('Vivamus', 1), ('adipiscing', 1), ('ante', 1), ('augue', 1), ('a', 1), ('commodo', 1), ('congue', 1), ('consectetur', 1), ('dapibus', 1), ('egestas', 1), ('elit', 1), ('ex', 1), ('feugiat', 1), ('finibus', 1), ('iaculis', 1), ('in', 1), ('justo', 1), ('lacus', 1), ('leo', 1), ('libero', 1), ('magna', 1), ('nibh', 1), ('nisl', 1), ('nulla', 1), ('odio', 1), ('placerat', 1), ('pulvinar', 1), ('purus', 1), ('quis', 1), ('rhoncus', 1), ('sapien', 1), ('scelerisque', 1), ('sed', 1), ('semper', 1), ('sem', 1), ('sodales', 1), ('tincidunt', 1), ('tristique', 1), ('urna', 1), ('ut', 1), ('vehicula', 1), ('vel', 1), ('vitae', 1), ('viverra', 1), ('volutpat', 1)]
assert remove_stop_words(tokenized_list_sample_2, file_lang) == ['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Sed', 'congue', 'dapibus', 'cursus', '.', 'Aenean', 'volutpat', 'ex', 'sit', 'amet', 'purus', 'tincidunt', 'accumsan', '.', 'In', 'non', 'rhoncus', 'augue', '.', 'Maecenas', 'pulvinar', 'placerat', 'accumsan', '.', 'Cras', 'vehicula', ',', 'ipsum', 'non', 'condimentum', 'tristique', ',', 'lacus', 'nulla', 'cursus', 'sem', ',', 'et', 'feugiat', 'massa', 'libero', 'et', 'massa', '.', 'Vivamus', 'ut', 'magna', 'ac', 'massa', 'egestas', 'iaculis', 'a', 'sit', 'amet', 'nibh', '.', 'Quisque', 'sed', 'ante', 'sodales', ',', 'cursus', 'sapien', 'ac', ',', 'finibus', 'urna', '.', 'Curabitur', 'vitae', 'dolor', 'in', 'odio', 'viverra', 'scelerisque', '.', 'Donec', 'condimentum', 'leo', 'justo', ',', 'quis', 'commodo', 'nisl', 'semper', 'vel', '.']

print('\n\n Test With greek_sample.txt \n\n')

greek_text_sample = get_the_content_of_a_file('tests/files/greek_sample.txt')
greek_tokenized_list_sample = tokenization(greek_text_sample)
file_lang = identify_lang_of_a_given_file(greek_text_sample)

assert sum_of_paragraphs(greek_text_sample) == 7, 'Should be 1'
assert sum_of_sentences(greek_text_sample) == 7, 'Should be 10'
assert greek_tokenized_list_sample == ['Τεράστια', 'είναι', 'φέτος', 'η', 'ζήτηση', 'για', 'ελληνικές', 'εξοχικές', 'κατοικίες', 'από', 'Βρετανούς', ',', 'χάρη', 'στο', 'άνοιγμα', 'του', 'τουρισμού', 'χωρίς', 'καραντίνα', ',', 'σύμφωνα', 'με', 'βρετανικό', 'δημοσίευμα', ',', 'με', 'τους', 'δημοφιλέστερους', 'προορισμούς', 'όπως', 'Μύκονος', ',', 'Σαντορίνη', 'και', 'Κέρκυρα', 'να', 'είναι', 'ήδη', 'κλεισμένοι', ',', 'ακόμη', 'και', 'από', 'επαγγελματίες', 'που', 'θα', 'έρθουν', 'να', 'εργαστούν', 'από', 'την…', 'παραλία', '.', 'Όπως', 'αναφέρει', 'η', 'συμβουλευτική', 'εταιρία', 'για', 'τουριστικά', 'θέματα', 'PC', 'Agency', 'στην', 'εφημερίδα', 'Daily', 'Mail', ',', 'καταγράφεται', 'αύξηση', 'στη', 'ζήτηση', 'για', 'πολυτελείς', 'εξοχικές', 'κατοικίες', 'στην', 'Πορτογαλία', 'και', 'στη', 'Μαγιόρκα', ',', 'αλλά', 'ακόμη', 'περισσότερο', 'στην', 'Ελλάδα', ',', 'μετά', 'την', 'ανακοίνωση', 'του', 'ανοίγματος', 'του', 'ελληνικού', 'τουρισμού', 'από', 'τα', 'μέσα', 'Μαΐου', '.', 'Οι', 'Άγγλοι', 'ειδικοί', 'τονίζουν', 'ότι', 'καταγράφεται', 'μεγάλος', 'αριθμός', 'επαγγελματιών', 'οι', 'οποίοι', 'κλείνουν', 'εισιτήρια', 'και', 'διαμονή', 'ενός', 'μηνός', 'σε', 'βίλες', 'στην', 'Ελλάδα', ',', 'ζητώντας', 'να', 'υπάρχει', 'ασύρματο', 'Ίντερνετ', 'και', 'γραφείο', 'διαθέσιμο', ',', 'ενώ', 'θα', 'έχουν', 'μαζί', 'τους', 'όλη', 'την', 'οικογένεια', 'ώστε', 'να', 'εργάζονται', 'και', 'να', 'πληρώνονται', 'κανονικά', 'ενώ', 'κάνουν', 'διακοπές', 'με', 'την', 'οικογένειά', 'τους', '.', 'Σύμφωνα', 'με', 'την', 'PC', 'Agency', ',', 'σε', 'σύγκριση', 'με', 'τα', 'προηγούμενα', 'χρόνια', '(', 'όχι', 'το', '2020', ')', 'έχουν', 'διπλασιαστεί', 'τα', 'αιτήματα', 'για', 'ενοικίαση', 'εξοχικών', 'κατοικιών', 'στην', 'Ελλάδα', ',', 'με', 'μεγάλη', 'ζήτηση', 'για', 'πλήρως', 'εξοπλισμένες', 'βίλες', 'με', 'προσωπικό', '(', 'μάγειρα', ',', 'μπάτλερ', 'κλπ', ')', 'ώστε', 'οι', 'επισκέπτες', 'να', 'μένουν', 'μακριά', 'από', 'πολύβουα', 'εστιατόρια', '.', 'Αναφέρεται', 'συγκεκριμένα', 'ότι', 'δημοφιλείς', 'προορισμοί', 'όπως', 'η', 'Μύκονος', ',', 'η', 'Σαντορίνη', ',', 'η', 'Κέρκυρα', 'και', 'η', 'Κρήτη', 'έχουν', 'ήδη', 'κλείσει', 'αναφορικά', 'με', 'τις', 'πολυτελείς', 'εξοχικές', 'τους', 'κατοικίες', ',', 'με', 'πολλές', 'κρατήσεις', 'να', 'είναι', 'εκείνες', 'που', 'αναβλήθηκαν', 'το', '2020', '.', 'Το', 'δημοσίευμα', 'αναφέρει', 'επίσης', 'ότι', 'τα', 'στοιχεία', 'της', 'αγοράς', 'στη', 'Βρετανία', 'δείχνουν', 'πως', 'πολλοί', 'κλείνουν', 'επίσης', 'κατοικίες', 'σε', 'μικρότερα', 'νησιά', 'μακριά', 'από', 'τον', 'πολύ', 'κόσμο', ',', 'φέρνοντας', 'ως', 'παραδείγματα', 'την', 'Ύδρα', ',', 'τους', 'Παξούς', 'και', 'τη', 'Σύρο', '.', 'Τονίζεται', 'πάντως', 'ότι', 'η', 'βρετανική', 'κυβέρνηση', 'είναι', 'απίθανο', 'να', 'συμπεριλάβει', 'την', 'Ελλάδα', 'στη', 'λεγόμενη', 'πράσινη', 'λίστα', 'της', 'για', 'τον', 'Μάιο', ',', 'η', 'οποία', 'δεν', 'απαιτεί', 'καραντίνα', 'κατά', 'την', 'επιστροφή', 'από', 'ελληνικά', 'αεροδρόμια', ',', 'λόγω', 'του', 'υψηλού', 'ποσοστού', 'κρουσμάτων', 'που', 'έχει', 'η', 'χώρα', '.']
# assert sum_of_distinct_word_types(greek_tokenized_list_sample) == {'NN': 42, 'NNS': 13, 'AT': 9, 'VBD': 2, 'VBG': 1}
# assert token_frequency(greek_tokenized_list_sample) == [('.', 10), (',', 7), ('amet', 3), ('cursus', 3), ('massa', 3), ('sit', 3), ('accumsan', 2), ('ac', 2), ('condimentum', 2), ('dolor', 2), ('et', 2), ('ipsum', 2), ('non', 2), ('Aenean', 1), ('Cras', 1), ('Curabitur', 1), ('Donec', 1), ('In', 1), ('Lorem', 1), ('Maecenas', 1), ('Quisque', 1), ('Sed', 1), ('Vivamus', 1), ('adipiscing', 1), ('ante', 1), ('augue', 1), ('a', 1), ('commodo', 1), ('congue', 1), ('consectetur', 1), ('dapibus', 1), ('egestas', 1), ('elit', 1), ('ex', 1), ('feugiat', 1), ('finibus', 1), ('iaculis', 1), ('in', 1), ('justo', 1), ('lacus', 1), ('leo', 1), ('libero', 1), ('magna', 1), ('nibh', 1), ('nisl', 1), ('nulla', 1), ('odio', 1), ('placerat', 1), ('pulvinar', 1), ('purus', 1), ('quis', 1), ('rhoncus', 1), ('sapien', 1), ('scelerisque', 1), ('sed', 1), ('semper', 1), ('sem', 1), ('sodales', 1), ('tincidunt', 1), ('tristique', 1), ('urna', 1), ('ut', 1), ('vehicula', 1), ('vel', 1), ('vitae', 1), ('viverra', 1), ('volutpat', 1)]
assert remove_stop_words(greek_tokenized_list_sample, file_lang) == ['Τεράστια', 'φέτος', 'ζήτηση', 'ελληνικές', 'εξοχικές', 'κατοικίες', 'Βρετανούς', ',', 'χάρη', 'άνοιγμα', 'τουρισμού', 'χωρίς', 'καραντίνα', ',', 'σύμφωνα', 'βρετανικό', 'δημοσίευμα', ',', 'δημοφιλέστερους', 'προορισμούς', 'όπως', 'Μύκονος', ',', 'Σαντορίνη', 'Κέρκυρα', 'ήδη', 'κλεισμένοι', ',', 'ακόμη', 'επαγγελματίες', 'έρθουν', 'εργαστούν', 'την…', 'παραλία', '.', 'Όπως', 'αναφέρει', 'συμβουλευτική', 'εταιρία', 'τουριστικά', 'θέματα', 'PC', 'Agency', 'εφημερίδα', 'Daily', 'Mail', ',', 'καταγράφεται', 'αύξηση', 'ζήτηση', 'πολυτελείς', 'εξοχικές', 'κατοικίες', 'Πορτογαλία', 'Μαγιόρκα', ',', 'αλλά', 'ακόμη', 'περισσότερο', 'Ελλάδα', ',', 'ανακοίνωση', 'ανοίγματος', 'ελληνικού', 'τουρισμού', 'μέσα', 'Μαΐου', '.', 'Άγγλοι', 'ειδικοί', 'τονίζουν', 'καταγράφεται', 'μεγάλος', 'αριθμός', 'επαγγελματιών', 'οποίοι', 'κλείνουν', 'εισιτήρια', 'διαμονή', 'ενός', 'μηνός', 'βίλες', 'Ελλάδα', ',', 'ζητώντας', 'υπάρχει', 'ασύρματο', 'Ίντερνετ', 'γραφείο', 'διαθέσιμο', ',', 'έχουν', 'μαζί', 'όλη', 'οικογένεια', 'ώστε', 'εργάζονται', 'πληρώνονται', 'κανονικά', 'κάνουν', 'διακοπές', 'οικογένειά', '.', 'Σύμφωνα', 'PC', 'Agency', ',', 'σύγκριση', 'προηγούμενα', 'χρόνια', '(', 'όχι', '2020', ')', 'έχουν', 'διπλασιαστεί', 'αιτήματα', 'ενοικίαση', 'εξοχικών', 'κατοικιών', 'Ελλάδα', ',', 'μεγάλη', 'ζήτηση', 'πλήρως', 'εξοπλισμένες', 'βίλες', 'προσωπικό', '(', 'μάγειρα', ',', 'μπάτλερ', 'κλπ', ')', 'ώστε', 'επισκέπτες', 'μένουν', 'μακριά', 'πολύβουα', 'εστιατόρια', '.', 'Αναφέρεται', 'συγκεκριμένα', 'δημοφιλείς', 'προορισμοί', 'όπως', 'Μύκονος', ',', 'Σαντορίνη', ',', 'Κέρκυρα', 'Κρήτη', 'έχουν', 'ήδη', 'κλείσει', 'αναφορικά', 'τις', 'πολυτελείς', 'εξοχικές', 'κατοικίες', ',', 'πολλές', 'κρατήσεις', 'εκείνες', 'αναβλήθηκαν', '2020', '.', 'Το', 'δημοσίευμα', 'αναφέρει', 'επίσης', 'στοιχεία', 'της', 'αγοράς', 'Βρετανία', 'δείχνουν', 'πολλοί', 'κλείνουν', 'επίσης', 'κατοικίες', 'μικρότερα', 'νησιά', 'μακριά', 'πολύ', 'κόσμο', ',', 'φέρνοντας', 'ως', 'παραδείγματα', 'Ύδρα', ',', 'Παξούς', 'τη', 'Σύρο', '.', 'Τονίζεται', 'πάντως', 'βρετανική', 'κυβέρνηση', 'απίθανο', 'συμπεριλάβει', 'Ελλάδα', 'λεγόμενη', 'πράσινη', 'λίστα', 'της', 'Μάιο', ',', 'οποία', 'απαιτεί', 'καραντίνα', 'επιστροφή', 'ελληνικά', 'αεροδρόμια', ',', 'λόγω', 'υψηλού', 'ποσοστού', 'κρουσμάτων', 'έχει', 'χώρα', '.']

