"""
Mike-George Verros
ITC6010A1 - NATURAL LANGUAGE PROCESSING - SPRING TERM 2021
HW#1
I create simple tests in order to be 100% confident that one slice change does not affect the results
"""

from functions.functions import *

print('\n\n Test With sample-text.txt \n\n')

txt = open(get_sample_text_file_path()).read()

sanitized_str = sanitize_string(txt)
removed_stop_word_txt = remove_stop_words(sanitized_str)
tokenized_txt = tokenization(txt)

assert sum_of_paragraphs(txt) == 8, 'Should be 8'
assert sum_of_sentences(txt) == 30, 'Should be 30'
assert sum_of_words(txt) == 442, 'Should be 442'
assert sum_of_distinct_words(txt) == 283, 'Should be 283'  # ERROR
assert len(removed_stop_word_txt) == 268, 'Should be 268'
assert removed_stop_word_txt == ['Here', 'random', 'sentences', 'If', 'really', 'see', 'future', 'couldve', 'prevented', 'I', 'report', 'really', 'beautiful', 'example', 'I', 'heard', 'favorite', 'public', 'radio', 'station', 'Feb', '16', 'recent', 'fund', 'drive', 'Ive', 'met', 'member', 'developmember', 'staff', 'interviewed', 'I', 'wont', 'name', 'simply', 'might', 'embarrassed', 'I', 'wouldnt', 'want', 'cause', 'This', 'powerful', 'true', 'story', 'human', 'decency', 'courage', 'rare', 'tragic', 'annals', 'World', 'War', 'II', 'badly', 'spoiled', 'terrible', 'writing', 'Many', 'reviews', 'explain', 'makes', 'writing', 'bad', 'eg', 'John', 'Sollamis', '3', 'star', 'review', 'comments', 'I', 'wont', 'Its', 'repetitive', 'slow', 'interesting', 'I', 'think', 'I', 'read', 'word', 'saumensch', 'saukerl', 'one', 'time', 'Ill', 'done', 'book', 'forever', 'Because', 'havent', 'sopped', 'enough', 'yet', 'life', 'right', 'By', 'far', 'favorite', 'book', 'The', 'language', 'beautiful', 'imaginative', 'cant', 'help', 'fall', 'love', 'characters', 'You', 'studied', 'WW2', 'extensively', 'along', 'love', 'fiction', 'struggle', 'theme', 'thats', 'projected', 'whole', 'book', 'Little', 'know', 'fled', 'london', 'theyre', 'forced', 'stay', 'Maries', 'great', 'uncle', 'Etienne', 'remain', 'hidden', 'Intriguing', 'story', 'I', 'love', 'book', 'arranged:', 'parallel', 'narration', 'third', 'person', 'perspective', 'chapter', 'chapter', 'changing', 'view', 'brought', 'new', 'characters', 'happening', 'along', 'theme', 'The', 'characters', 'connected', 'yet', 'seemingly', 'disconnected', 'Its', 'like', 'watching', 'movie', 'reader', 'camera:', 'know', 'sides', 'dont', 'know', 'going', 'It', 'keeps', 'reader', 'engaged', 'Definitely', 'page', 'turner', 'He', 'drives', 'slow', 'uses', 'shoehorn', 'doesnt', 'know', 'hybrid', 'cars', 'disagrees', 'using', 'credit', 'cards', 'shopping', 'doesnt', 'use', 'coffee', 'maker', 'percolator', 'perfectly', 'fine', 'etc', 'Im', 'sorry', 'age', '59', 'doesnt', 'fit', 'story', 'Ove', 'comes', 'like', 'cat', 'suddenly', 'theyre', 'best', 'friends', 'At', 'least', 'storys', 'predictability', 'saved', 'fretting', 'incessantly', 'cat', 'Shes', 'take', 'prisoners', 'fireball', 'Hes', 'sweet', 'talking', 'charmer', 'It', 'could', 'love', 'dont', 'kill', 'first', 'Enemies', 'lovers', 'romance', 'It', 'wouldnt', 'wouldntve', 'bothered', 'appeared', 'dialogue', 'I', 'recall', 'occured', 'several', 'times', 'narrative', 'I', 'started', 'comment', 'say', 'spelling', 'correction', 'explanation', 'seemed', 'less', 'likely', 'examples', 'things', 'separating']
assert get_words(sanitized_str) == ['Here', 'are', 'some', 'random', 'sentences', 'If', 'you', 'can', 'really', 'see', 'the', 'future', 'you', 'couldve', 'prevented', 'all', 'of', 'this', 'I', 'just', 'have', 'to', 'report', 'a', 'really', 'beautiful', 'example', 'I', 'heard', 'on', 'my', 'favorite', 'public', 'radio', 'station', 'on', 'Feb', '16', 'during', 'their', 'recent', 'fund', 'drive', 'Ive', 'met', 'a', 'member', 'of', 'their', 'developmember', 'staff', 'and', 'been', 'interviewed', 'by', 'her', 'I', 'wont', 'name', 'her', 'simply', 'because', 'she', 'might', 'be', 'embarrassed', 'and', 'I', 'wouldnt', 'want', 'to', 'cause', 'that', 'This', 'powerful', 'true', 'story', 'of', 'human', 'decency', 'and', 'courage', 'so', 'rare', 'in', 'the', 'tragic', 'annals', 'of', 'World', 'War', 'II', 'is', 'badly', 'spoiled', 'by', 'terrible', 'writing', 'Many', 'of', 'the', 'reviews', 'here', 'explain', 'just', 'what', 'makes', 'the', 'writing', 'so', 'bad', 'eg', 'John', 'Sollamis', '3', 'star', 'review', 'and', 'comments', 'on', 'it', 'so', 'I', 'wont', 'do', 'that', 'here', 'Its', 'repetitive', 'slow', 'not', 'interesting', 'and', 'I', 'think', 'if', 'I', 'have', 'to', 'read', 'the', 'word', 'saumensch', 'or', 'saukerl', 'one', 'more', 'time', 'Ill', 'be', 'done', 'with', 'this', 'book', 'forever', 'Because', 'you', 'havent', 'sopped', 'up', 'enough', 'of', 'that', 'yet', 'in', 'your', 'life', 'right', 'By', 'far', 'my', 'favorite', 'book', 'The', 'language', 'is', 'beautiful', 'and', 'imaginative', 'and', 'you', 'cant', 'help', 'but', 'fall', 'in', 'love', 'with', 'the', 'characters', 'You', 'have', 'to', 'have', 'studied', 'WW2', 'extensively', 'along', 'with', 'the', 'love', 'for', 'fiction', 'and', 'the', 'struggle', 'theme', 'thats', 'projected', 'through', 'this', 'whole', 'book', 'Little', 'do', 'they', 'know', 'he', 'has', 'fled', 'to', 'london', 'and', 'theyre', 'forced', 'to', 'stay', 'with', 'Maries', 'great', 'uncle', 'Etienne', 'where', 'they', 'remain', 'hidden', 'Intriguing', 'story', 'I', 'love', 'how', 'the', 'book', 'is', 'arranged:', 'parallel', 'narration', 'third', 'person', 'perspective', 'chapter', 'by', 'chapter', 'with', 'a', 'changing', 'view', 'brought', 'by', 'new', 'characters', 'of', 'what', 'is', 'happening', 'along', 'the', 'theme', 'The', 'characters', 'are', 'all', 'connected', 'yet', 'seemingly', 'disconnected', 'Its', 'like', 'watching', 'a', 'movie', 'with', 'the', 'reader', 'as', 'the', 'camera:', 'we', 'know', 'all', 'the', 'sides', 'but', 'we', 'dont', 'know', 'how', 'it', 'is', 'going', 'It', 'keeps', 'the', 'reader', 'engaged', 'Definitely', 'a', 'page', 'turner', 'He', 'drives', 'slow', 'uses', 'a', 'shoehorn', 'doesnt', 'know', 'about', 'hybrid', 'cars', 'disagrees', 'with', 'using', 'credit', 'cards', 'for', 'shopping', 'doesnt', 'use', 'a', 'coffee', 'maker', 'because', 'a', 'percolator', 'is', 'perfectly', 'fine', 'etc', 'Im', 'sorry', 'but', 'age', '59', 'just', 'doesnt', 'fit', 'the', 'story', 'Ove', 'comes', 'to', 'like', 'the', 'cat', 'and', 'suddenly', 'theyre', 'best', 'friends', 'At', 'least', 'the', 'storys', 'predictability', 'saved', 'me', 'from', 'fretting', 'incessantly', 'about', 'the', 'cat', 'Shes', 'a', 'take', 'no', 'prisoners', 'fireball', 'Hes', 'a', 'sweet', 'talking', 'charmer', 'It', 'could', 'be', 'love', 'if', 'they', 'dont', 'kill', 'each', 'other', 'first', 'Enemies', 'to', 'lovers', 'romance', 'It', 'wouldnt', 'have', 'wouldntve', 'of', 'had', 'bothered', 'me', 'if', 'it', 'only', 'appeared', 'in', 'dialogue', 'but', 'I', 'recall', 'it', 'occured', 'several', 'times', 'in', 'the', 'narrative', 'by', 'I', 'started', 'this', 'comment', 'to', 'say', 'that', 'the', 'spelling', 'correction', 'explanation', 'seemed', 'less', 'likely', 'in', 'examples', 'with', 'things', 'separating', 'the', 'of', 'and', 'have']
assert word_frequency(tokenized_txt) == [('.', 35), ('the', 21), (',', 17), ('and', 11), ('I', 10), ('a', 10), ('to', 9), ('of', 8), ('with', 8), ('in', 6), ('is', 6), ('by', 5), ('have', 5), ('book', 4), ('but', 4), ('it', 4), ('know', 4), ('love', 4), ('that', 4), ('this', 4), ('you', 4), ('(', 3), (')', 3), ('It', 3), ('all', 3), ('be', 3), ('characters', 3), ("doesn't", 3), ('if', 3), ('just', 3), ('on', 3), ('so', 3), ('story', 3), ('they', 3), ('!', 2), (':', 2), ("It's", 2), ('The', 2), ('about', 2), ('along', 2), ('are', 2), ('beautiful', 2), ('because', 2), ('cat', 2), ('chapter', 2), ("don't", 2), ('do', 2), ('favorite', 2), ('for', 2), ('here', 2), ('her', 2), ('how', 2), ('like', 2), ('me', 2), ('my', 2), ('reader', 2), ('really', 2), ('slow', 2), ('their', 2), ('theme', 2), ("they're", 2), ('we', 2), ('what', 2), ("won't", 2), ("wouldn't", 2), ('writing', 2), ('yet', 2), ('"saukerl"', 1), ('"saumensch"', 1), ("'have'", 1), ("'of'", 1), ("'spelling", 1), ('16', 1), ('3-star', 1), ('59', 1), ('At', 1), ('Because', 1), ('By', 1), ('Definitely', 1), ('Enemies', 1), ('Etienne', 1), ('Feb', 1), ("He's", 1), ('Here', 1), ('He', 1), ("I'll", 1), ("I'm", 1), ("I've", 1), ('II', 1), ('If', 1), ('Intriguing', 1), ('John', 1), ('Little', 1), ('Many', 1), ("Marie's", 1), ('Ove', 1), ("She's", 1), ("Sollami's", 1), ('This', 1), ('WW2', 1), ('War', 1), ('World', 1), ('You', 1), ('age', 1), ('annals', 1), ('appeared', 1), ('arranged', 1), ('as', 1), ('badly', 1), ('bad', 1), ('been', 1), ('best', 1), ('bothered', 1), ('brought', 1), ('camera', 1), ("can't", 1), ('can', 1), ('cards', 1), ('cars', 1), ('cause', 1), ('changing', 1), ('charmer', 1), ('coffee', 1), ('comes', 1), ('comments', 1), ('comment', 1), ('connected', 1), ("correction'", 1), ("could've", 1), ('could', 1), ('courage', 1), ('credit', 1), ('decency', 1), ('developmember', 1), ('dialogue', 1), ('disagrees', 1), ('disconnected', 1), ('done', 1), ('drives', 1), ('drive', 1), ('during', 1), ('each', 1), ('embarrassed', 1), ('engaged', 1), ('enough', 1), ('etc', 1), ('examples', 1), ('example', 1), ('explain', 1), ('explanation', 1), ('extensively', 1), ('e', 1), ('fall', 1), ('far', 1), ('fiction', 1), ('fine', 1), ('fireball', 1), ('first', 1), ('fit', 1), ('fled', 1), ('forced', 1), ('forever', 1), ('fretting', 1), ('friends', 1), ('from', 1), ('fund', 1), ('future', 1), ('going', 1), ('great', 1), ('g', 1), ('had?', 1), ('happening', 1), ('has', 1), ("haven't", 1), ('heard', 1), ('help', 1), ('he', 1), ('hidden', 1), ('human', 1), ('hybrid', 1), ('imaginative', 1), ('incessantly', 1), ('interesting', 1), ('interviewed', 1), ('keeps', 1), ('kill', 1), ('language', 1), ('least', 1), ('less', 1), ('life', 1), ('likely', 1), ('london', 1), ('lovers', 1), ('maker', 1), ('makes', 1), ('member', 1), ('met', 1), ('might', 1), ('more', 1), ('movie', 1), ('name', 1), ('narration', 1), ('narrative', 1), ('new', 1), ('not', 1), ('occured', 1), ('one', 1), ('only', 1), ('or', 1), ('other', 1), ('page-turner', 1), ('parallel', 1), ('percolator', 1), ('perfectly', 1), ('perspective', 1), ('powerful', 1), ('predictability', 1), ('prevented', 1), ('projected', 1), ('public', 1), ('radio', 1), ('random', 1), ('rare', 1), ('read', 1), ('recall', 1), ('recent', 1), ('remain', 1), ('repetitive', 1), ('report', 1), ('reviews', 1), ('review', 1), ('right?', 1), ('romance', 1), ('saved', 1), ('say', 1), ('seemed', 1), ('seemingly', 1), ('see', 1), ('sentences', 1), ('separating', 1), ('several', 1), ('she', 1), ('shoehorn', 1), ('shopping', 1), ('sides', 1), ('simply', 1), ('some', 1), ('sopped', 1), ('sorry', 1), ('spoiled', 1), ('staff', 1), ('started', 1), ('station', 1), ('stay', 1), ("story's", 1), ('struggle', 1), ('studied', 1), ('suddenly', 1), ('sweet-talking', 1), ('take-no-prisoners', 1), ('terrible', 1), ("that's", 1), ('things', 1), ('think', 1), ('third-person', 1), ('through', 1), ('times', 1), ('time', 1), ('tragic', 1), ('true', 1), ('uncle', 1), ('up', 1), ('uses', 1), ('use', 1), ('using', 1), ('view', 1), ('want', 1), ('watching', 1), ('where', 1), ('whole', 1), ('word', 1), ("wouldn't've", 1), ('your', 1)]


print('\n\n Test With sample1.txt \n\n')

txt_sample_1 = open('files/sample1.txt').read()

sanitized_str = sanitize_string(txt_sample_1)
removed_stop_word_txt = remove_stop_words(sanitized_str)
tokenized_txt = tokenization(txt_sample_1)

assert sum_of_paragraphs(txt_sample_1) == 3, 'Should be 3'
assert sum_of_sentences(txt_sample_1) == 15, 'Should be 15'
assert sum_of_words(txt_sample_1) == 88, 'Should be 88'
# assert sum_of_distinct_words(txt_sample_1) == 88, 'Should be 88'  # ERROR
assert len(removed_stop_word_txt) == 85, 'Should be 85'
assert removed_stop_word_txt == ['Utilitatis', 'causa', 'amicitia', 'est', 'quaesita', 'Lorem', 'ipsum', 'dolor', 'sit', 'amet', 'consectetur', 'adipiscing', 'elit', 'Collatio', 'igitur', 'ista', 'te', 'nihil', 'iuvat', 'Honesta', 'oratio', 'Socratica', 'Platonis', 'etiam', 'Primum', 'nostrane', 'potestate', 'est', 'quid', 'meminerimus', 'Duo', 'Reges:', 'constructio', 'interrete', 'Quid', 'si', 'etiam', 'iucunda', 'memoria', 'est', 'praeteritorum', 'malorum', 'Si', 'quidem', 'inquit', 'tollerem', 'sed', 'relinquo', 'An', 'nisi', 'populari', 'fama', 'Quamquam', 'id', 'quidem', 'licebit', 'iis', 'existimare', 'qui', 'legerint', 'Summum', 'vobis', 'bonum', 'voluptas', 'dicitur', 'At', 'hoc', 'eo', 'M', 'Refert', 'tamen', 'quo', 'modo', 'Quid', 'sequatur', 'quid', 'repugnet', 'vident', 'Iam', 'id', 'ipsum', 'absurdum', 'maximum', 'malum', 'neglegi']
assert get_words(sanitized_str) == ['Utilitatis', 'causa', 'amicitia', 'est', 'quaesita', 'Lorem', 'ipsum', 'dolor', 'sit', 'amet', 'consectetur', 'adipiscing', 'elit', 'Collatio', 'igitur', 'ista', 'te', 'nihil', 'iuvat', 'Honesta', 'oratio', 'Socratica', 'Platonis', 'etiam', 'Primum', 'in', 'nostrane', 'potestate', 'est', 'quid', 'meminerimus', 'Duo', 'Reges:', 'constructio', 'interrete', 'Quid', 'si', 'etiam', 'iucunda', 'memoria', 'est', 'praeteritorum', 'malorum', 'Si', 'quidem', 'inquit', 'tollerem', 'sed', 'relinquo', 'An', 'nisi', 'populari', 'fama', 'Quamquam', 'id', 'quidem', 'licebit', 'iis', 'existimare', 'qui', 'legerint', 'Summum', 'a', 'vobis', 'bonum', 'voluptas', 'dicitur', 'At', 'hoc', 'in', 'eo', 'M', 'Refert', 'tamen', 'quo', 'modo', 'Quid', 'sequatur', 'quid', 'repugnet', 'vident', 'Iam', 'id', 'ipsum', 'absurdum', 'maximum', 'malum', 'neglegi']
assert word_frequency(tokenized_txt) == [(',', 13), ('.', 12), ('est', 3), ('Quid', 2), ('etiam', 2), ('id', 2), ('in', 2), ('ipsum', 2), ('quidem', 2), ('quid', 2), (':', 1), ('An', 1), ('At', 1), ('Collatio', 1), ('Duo', 1), ('Honesta', 1), ('Iam', 1), ('Lorem', 1), ('M', 1), ('Platonis', 1), ('Primum', 1), ('Quamquam', 1), ('Refert', 1), ('Reges', 1), ('Si', 1), ('Socratica', 1), ('Summum', 1), ('Utilitatis', 1), ('absurdum', 1), ('adipiscing', 1), ('amet', 1), ('amicitia', 1), ('a', 1), ('bonum', 1), ('causa', 1), ('consectetur', 1), ('constructio', 1), ('dicitur', 1), ('dolor', 1), ('elit', 1), ('eo', 1), ('existimare', 1), ('fama?', 1), ('hoc', 1), ('igitur', 1), ('iis', 1), ('inquit', 1), ('interrete', 1), ('ista', 1), ('iucunda', 1), ('iuvat', 1), ('legerint', 1), ('licebit', 1), ('malorum?', 1), ('malum', 1), ('maximum', 1), ('meminerimus?', 1), ('memoria', 1), ('modo', 1), ('neglegi', 1), ('nihil', 1), ('nisi', 1), ('nostrane', 1), ('oratio', 1), ('populari', 1), ('potestate', 1), ('praeteritorum', 1), ('quaesita', 1), ('qui', 1), ('quo', 1), ('relinquo', 1), ('repugnet', 1), ('sed', 1), ('sequatur', 1), ('sit', 1), ('si', 1), ('tamen', 1), ('te', 1), ('tollerem', 1), ('vident', 1), ('vobis', 1), ('voluptas', 1)]